{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rick and Morty Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "topic_url = \"https://rickandmorty.fandom.com/wiki/Rickipedia\"\n",
    "\n",
    "response = requests.get(topic_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text\n",
    "page_contents[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "doc = BeautifulSoup(page_contents , 'html.parser')\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_link_tags = doc.find_all('a' , {'class' : 'image link-internal'})\n",
    "len(topics_link_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_url = 'https://rickandmorty.fandom.com' + topics_link_tags[8]['href']\n",
    "\n",
    "response_episode = requests.get(episode_url)\n",
    "episode_page_content = response_episode.text\n",
    "\n",
    "doc_episode = BeautifulSoup(episode_page_content , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_episode_tables = doc_episode.find_all('table')\n",
    "print(doc_episode_tables[1].find_all('a'))\n",
    "\n",
    "b_tag = doc_episode_tables[1].find_all('b')\n",
    "anchor_tag = b_tag[0].find('a')\n",
    "link = 'https://rickandmorty.fandom.com' +anchor_tag['href']\n",
    "print(anchor_tag[1]['title'])\n",
    "\n",
    "\n",
    "doc_episode_title = doc_episode.find_all('span' , {'class' : 'mw-headline'})\n",
    "\n",
    "print(doc_episode_title[2].contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_transcript(link , episode_num) :\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    response_episode_page = requests.get(link)\n",
    "    page_content = response_episode_page.text\n",
    "\n",
    "    doc_episode_page = BeautifulSoup(page_content , 'html.parser')\n",
    "    para_tags = doc_episode_page.find_all('p')\n",
    "\n",
    "    for tag in para_tags :\n",
    "        try :\n",
    "            if tag.find('b') == None:\n",
    "                continue\n",
    "            else :\n",
    "                list_child = list(tag.children)\n",
    "                dialouge = list_child[1]\n",
    "                \n",
    "                if list_child[0].find('a') == None :\n",
    "                    name = list_child[0].contents[0]\n",
    "                    # print(list_child[0].contents[0])\n",
    "\n",
    "                else :\n",
    "                    name = list_child[0].find('a').contents[0]\n",
    "                    # print(list_child[0].find('a').contents[0])\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        data.append([episode_num , name , dialouge])\n",
    "        \n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_season = []\n",
    "dataset_episode_title = []\n",
    "dataset = []\n",
    "\n",
    "j = 0\n",
    "for i in range(1 , 6):\n",
    "    # title = doc_episode_title[i+1].contents\n",
    "    # dataset_season.append(title)\n",
    "    table = doc_episode_tables[i]\n",
    "    anchor_tags = doc_episode_tables[i].find_all('a')\n",
    "    \n",
    "    for tags in anchor_tags :\n",
    "        \n",
    "        try :\n",
    "            dataset_episode_title.append(tags['title'])\n",
    "            link = 'https://rickandmorty.fandom.com' +tags['href'] + '/Transcript'\n",
    "            j+=1\n",
    "            print(link , j)\n",
    "            data = page_transcript(link=link , episode_num=j)\n",
    "            dataset.append(data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "   \n",
    "    \n",
    "print(dataset_episode_title)\n",
    "\n",
    "print(dataset_season)\n",
    "# dataset_episode_number = np.linspace(0 , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All content put in one p tag error\n",
    "\n",
    "\n",
    "url_error = \"https://rickandmorty.fandom.com/wiki/Pickle_Rick/Transcript\"\n",
    "\n",
    "response_error = requests.get(url_error)\n",
    "content_error = response_error.text\n",
    "doc_episode_error = BeautifulSoup(content_error , 'html.parser')\n",
    "\n",
    "para_tag_error  = doc_episode_error.find('p')\n",
    "\n",
    "text_error = para_tag_error.get_text()\n",
    "text_error = text_error.rsplit(\"\\n\")\n",
    "\n",
    "for text_e in text_error :\n",
    "    try:\n",
    "        text_e_i = text_e.rsplit(': ')\n",
    "        dataset[23].append([24 , text_e_i[0] , text_e_i[1]])\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Content put in dd tag and p tag in place of p tag error\n",
    "\n",
    "url_error_2 = \"https://rickandmorty.fandom.com/wiki/The_Vat_of_Acid_Episode/Transcript\"\n",
    "response_error_2 = requests.get(url_error_2)\n",
    "content_error_2 = response_error_2.text\n",
    "doc_episode_error_2 = BeautifulSoup(content_error_2 , 'html.parser')\n",
    "\n",
    "dd_tag_error_2  = doc_episode_error_2.find_all('dd')\n",
    "para_tag_error_2 = doc_episode_error_2.find_all('p')\n",
    "print(para_tag_error_2)\n",
    "# text_error_2 = para_tag_error_2.get_text()\n",
    "\n",
    "for t in dd_tag_error_2 :\n",
    "    text_error_2 = t.get_text()\n",
    "    # print(t.contents)\n",
    "    sentences = text_error_2.rsplit(\"\\n\")\n",
    "    for text_e_2 in sentences :\n",
    "        try :\n",
    "            print(text_e_2)\n",
    "            text_e_i_2 = text_e_2.rsplit(': ')\n",
    "            dataset[38].append([39 , text_e_i_2[0] , text_e_i_2[1]])\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "para_tag_error_2 = doc_episode_error_2.find_all('p')\n",
    "# print(para_tag_error_2)\n",
    "\n",
    "for para_tags in para_tag_error_2 :\n",
    "    try :\n",
    "        para_tags_text = para_tags.get_text()\n",
    "        para_tags_text = para_tags_text.rsplit(\": \")\n",
    "        dataset[38].append([39 , para_tags_text[0] , para_tags_text[1]])\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All P tags no b tag error\n",
    "\n",
    "url_error_4 = \"https://rickandmorty.fandom.com/wiki/Rest_and_Ricklaxation/Transcript\"\n",
    "response_error_4 = requests.get(url_error_4)\n",
    "content_error_4 = response_error_4.text\n",
    "doc_episode_error_4 = BeautifulSoup(content_error_4 , 'html.parser')\n",
    "\n",
    "para_tag_error_4 = doc_episode_error_4.find_all('p')\n",
    "para_tag_error_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for para_tags_4 in para_tag_error_4 :\n",
    "    try :\n",
    "        para_tags_text_4 = para_tags_4.get_text()\n",
    "        para_tags_text_4 = para_tags_text_4.rsplit(\": \")\n",
    "        dataset[26].append([27 , para_tags_text_4[0] , para_tags_text_4[1]])\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriving missing content from other site error\n",
    "\n",
    "url_error_3 = \"http://rickandmorty.newtfire.org/transcripts.html\"\n",
    "response_error_3 = requests.get(url_error_3)\n",
    "content_error_3 = response_error_3.text\n",
    "doc_episode_error_3 = BeautifulSoup(content_error_3 , 'html.parser')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_0 = doc_episode_error_3.find('div' , id = 'aboutopt26')\n",
    "print(opt_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_0_speaker = opt_0.find_all('span' , {'class':'speaker'})\n",
    "opt_0_speech = opt_0.find_all('span' , {'class':'speech'})\n",
    "# print(len(opt_0_speaker))\n",
    "# print(len(opt_0_speech))\n",
    "for i in range (0 , len(opt_0_speaker)):\n",
    "     dataset[26].append([27 , opt_0_speaker[i].get_text() , opt_0_speech[i].get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_np = dataset_np.squeeze()\n",
    "dataset_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['episode no.' , 'speaker' , 'dialouge']\n",
    "\n",
    "df = pd.DataFrame(dataset[0] , columns=col)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1 , 51) :\n",
    "    df_temp = pd.DataFrame(dataset[i] , columns=col)\n",
    "    df = df.append(df_temp , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Rick&Morty.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
